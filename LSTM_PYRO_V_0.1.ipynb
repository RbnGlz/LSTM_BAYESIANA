{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed9fbfb2-2ae7-4480-bb69-3736255fde61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Información del Sistema =====\n",
      "CUDA disponible: True\n",
      "Versión CUDA: 11.8\n",
      "Número de GPUs: 1\n",
      "GPU actual: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "cuDNN disponible: True\n",
      "Versión cuDNN: 90100\n",
      "Versión Pyro: 1.9.1\n",
      "Versión PyTorch: 2.6.0+cu118\n",
      "=================================\n",
      "Dispositivo seleccionado: cuda\n",
      "Nombre de la GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "Tensor en dispositivo: tensor([[0.7199, 0.8336, 0.5788],\n",
      "        [0.7577, 0.7110, 0.9808],\n",
      "        [0.7698, 0.7932, 0.4157]], device='cuda:0')\n",
      "Muestra del modelo: tensor([-1.5095,  0.2916, -0.0107], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "                              ###############  LSTM_PYRO_V0 MEJORADA  ##################\n",
    "    \"\"\"\n",
    "    MEJORAS IMPLEMENTADAS\n",
    "\n",
    "    Manejo de excepciones:\n",
    "        Se agregó manejo de excepciones en todas las funciones para evitar fallos inesperados.\n",
    "        Se proporcionan valores predeterminados en caso de error.\n",
    "    Mejoras en la estructura:\n",
    "        Se creó una función run_demo() para ejecutar todo el proceso de demostración.\n",
    "    Mejoras en la documentación:\n",
    "        Se mejoraron los docstrings con más detalles y ejemplos.\n",
    "    Flexibilidad:\n",
    "        Se agregaron parámetros opcionales para personalizar el tamaño del tensor y la dimensión del modelo.\n",
    "    Consistencia:\n",
    "        Se utilizó tipado en todas las funciones.\n",
    "    \"\"\"\n",
    "# Importamos las bibliotecas necesarias\n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from typing import Tuple, Optional, Dict, Any\n",
    "\n",
    "def check_system_requirements() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Verifica y recopila información sobre los requisitos del sistema.\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, Any]: Diccionario con información del sistema\n",
    "        \n",
    "    Example:\n",
    "        >>> info = check_system_requirements()\n",
    "        >>> print(info['cuda_available'])\n",
    "        True\n",
    "    \"\"\"\n",
    "    try:\n",
    "        info = {\n",
    "            'cuda_available': torch.cuda.is_available(),\n",
    "            'cuda_version': torch.version.cuda if torch.cuda.is_available() else None,\n",
    "            'gpu_count': torch.cuda.device_count() if torch.cuda.is_available() else 0,\n",
    "            'gpu_name': torch.cuda.get_device_name(0) if torch.cuda.is_available() else None,\n",
    "            'pyro_version': pyro.__version__,\n",
    "            'pytorch_version': torch.__version__,\n",
    "            'cudnn_available': torch.backends.cudnn.enabled if torch.cuda.is_available() else False,\n",
    "            'cudnn_version': torch.backends.cudnn.version() if torch.cuda.is_available() and torch.backends.cudnn.enabled else None\n",
    "        }\n",
    "        return info\n",
    "    except Exception as e:\n",
    "        print(f\"Error al verificar requisitos del sistema: {e}\")\n",
    "        # Devolvemos un diccionario con valores predeterminados en caso de error\n",
    "        return {\n",
    "            'cuda_available': False,\n",
    "            'pyro_version': pyro.__version__,\n",
    "            'pytorch_version': torch.__version__,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "def print_system_info(info: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Imprime la información del sistema de manera formateada.\n",
    "    \n",
    "    Args:\n",
    "        info (Dict[str, Any]): Diccionario con información del sistema\n",
    "    \"\"\"\n",
    "    print(\"===== Información del Sistema =====\")\n",
    "    print(f\"CUDA disponible: {info['cuda_available']}\")\n",
    "    if info['cuda_available']:\n",
    "        print(f\"Versión CUDA: {info['cuda_version']}\")\n",
    "        print(f\"Número de GPUs: {info['gpu_count']}\")\n",
    "        print(f\"GPU actual: {info['gpu_name']}\")\n",
    "        print(f\"cuDNN disponible: {info['cudnn_available']}\")\n",
    "        if info['cudnn_available']:\n",
    "            print(f\"Versión cuDNN: {info['cudnn_version']}\")\n",
    "    print(f\"Versión Pyro: {info['pyro_version']}\")\n",
    "    print(f\"Versión PyTorch: {info['pytorch_version']}\")\n",
    "    if 'error' in info:\n",
    "        print(f\"Error encontrado: {info['error']}\")\n",
    "    print(\"=================================\")\n",
    "\n",
    "def setup_device() -> Tuple[torch.device, Optional[str]]:\n",
    "    \"\"\"\n",
    "    Configura y devuelve el dispositivo de cómputo apropiado (GPU CUDA o CPU).\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[torch.device, Optional[str]]: Una tupla que contiene:\n",
    "            - El dispositivo seleccionado (CUDA o CPU)\n",
    "            - El nombre de la GPU si CUDA está disponible, None en caso contrario\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Verificamos si CUDA está disponible y configuramos el dispositivo\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # Obtenemos el nombre de la GPU si usamos CUDA, None en caso contrario\n",
    "        gpu_name = torch.cuda.get_device_name(0) if device.type == \"cuda\" else None\n",
    "        return device, gpu_name\n",
    "    except Exception as e:\n",
    "        print(f\"Error al configurar el dispositivo: {e}\")\n",
    "        return torch.device(\"cpu\"), None\n",
    "\n",
    "def create_example_tensor(device: torch.device, size: Tuple[int, int] = (3, 3)) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Crea un tensor aleatorio de ejemplo en el dispositivo especificado.\n",
    "    \n",
    "    Args:\n",
    "        device (torch.device): El dispositivo donde crear el tensor\n",
    "        size (Tuple[int, int], optional): Tamaño del tensor. Por defecto (3, 3)\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Un tensor aleatorio del tamaño especificado\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generamos un tensor aleatorio en el dispositivo especificado\n",
    "        return torch.rand(size, device=device)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al crear tensor: {e}\")\n",
    "        # En caso de error, devolvemos un tensor en CPU\n",
    "        return torch.rand(size)\n",
    "\n",
    "def simple_normal_model(device: torch.device, dim: int = 3) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Define y ejecuta un modelo Pyro simple que muestrea de una distribución normal multivariada.\n",
    "    \n",
    "    Args:\n",
    "        device (torch.device): El dispositivo donde ejecutar el modelo\n",
    "        dim (int, optional): Dimensión del vector. Por defecto 3\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Una muestra de la distribución normal multivariada\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Creamos un tensor de medias (loc) con ceros\n",
    "        loc = torch.zeros(dim, device=device)\n",
    "        # Creamos un tensor de escala con unos\n",
    "        scale = torch.ones(dim, device=device)\n",
    "        # Muestreamos de la distribución normal y convertimos a evento\n",
    "        return pyro.sample(\"obs\", dist.Normal(loc, scale).to_event(1))\n",
    "    except Exception as e:\n",
    "        print(f\"Error en el modelo: {e}\")\n",
    "        # En caso de error, devolvemos un tensor en CPU\n",
    "        loc = torch.zeros(dim)\n",
    "        scale = torch.ones(dim)\n",
    "        return pyro.sample(\"obs\", dist.Normal(loc, scale).to_event(1))\n",
    "\n",
    "# Función para ejecutar una demostración completa\n",
    "def run_demo():\n",
    "    \"\"\"\n",
    "    Ejecuta una demostración completa del entorno PyTorch/Pyro con CUDA.\n",
    "    \"\"\"\n",
    "    # Verificamos los requisitos del sistema\n",
    "    system_info = check_system_requirements()\n",
    "    print_system_info(system_info)\n",
    "    \n",
    "    # Configuramos el dispositivo de cómputo\n",
    "    device, gpu_name = setup_device()\n",
    "    print(f\"Dispositivo seleccionado: {device}\")\n",
    "    if gpu_name:\n",
    "        print(f\"Nombre de la GPU: {gpu_name}\")\n",
    "    \n",
    "    # Creamos e imprimimos un tensor de ejemplo\n",
    "    tensor = create_example_tensor(device)\n",
    "    print(f\"Tensor en dispositivo: {tensor}\")\n",
    "    \n",
    "    # Generamos e imprimimos una muestra de la distribución normal\n",
    "    muestra = simple_normal_model(device)\n",
    "    print(f\"Muestra del modelo: {muestra}\")\n",
    "    \n",
    "    return {\n",
    "        'system_info': system_info,\n",
    "        'device': device,\n",
    "        'tensor': tensor,\n",
    "        'muestra': muestra\n",
    "    }\n",
    "\n",
    "# Bloque principal de ejecución\n",
    "if __name__ == \"__main__\":\n",
    "    run_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee8995c-27a2-4726-ab49-58a08f8c9849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:LSTM_PYRO]",
   "language": "python",
   "name": "conda-env-LSTM_PYRO-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
